{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd02cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import scipy.spatial as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "from handshape_feature_extractor import HandShapeFeatureExtractor\n",
    "from frameextractor import frameExtractor\n",
    "#BASE = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f0c032-d8f0-4ef0-ae24-456866a89346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortme(v):\n",
    "    return int(os.path.basename(v)[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0bc7763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['traindata\\\\00000.mp4', 'traindata\\\\00001.mp4', 'traindata\\\\00002.mp4', 'traindata\\\\00003.mp4', 'traindata\\\\00004.mp4', 'traindata\\\\00005.mp4', 'traindata\\\\00006.mp4', 'traindata\\\\00007.mp4', 'traindata\\\\00008.mp4', 'traindata\\\\00009.mp4', 'traindata\\\\00010.mp4', 'traindata\\\\00011.mp4', 'traindata\\\\00012.mp4', 'traindata\\\\00013.mp4', 'traindata\\\\00014.mp4', 'traindata\\\\00015.mp4', 'traindata\\\\00016.mp4', 'traindata\\\\00017.mp4', 'traindata\\\\00018.mp4', 'traindata\\\\00019.mp4', 'traindata\\\\00020.mp4', 'traindata\\\\00021.mp4', 'traindata\\\\00022.mp4', 'traindata\\\\00023.mp4', 'traindata\\\\00024.mp4', 'traindata\\\\00025.mp4', 'traindata\\\\00026.mp4', 'traindata\\\\00027.mp4', 'traindata\\\\00028.mp4', 'traindata\\\\00029.mp4', 'traindata\\\\00030.mp4', 'traindata\\\\00031.mp4', 'traindata\\\\00032.mp4', 'traindata\\\\00033.mp4', 'traindata\\\\00034.mp4', 'traindata\\\\00035.mp4', 'traindata\\\\00036.mp4', 'traindata\\\\00037.mp4', 'traindata\\\\00038.mp4', 'traindata\\\\00039.mp4', 'traindata\\\\00040.mp4', 'traindata\\\\00041.mp4', 'traindata\\\\00042.mp4', 'traindata\\\\00043.mp4', 'traindata\\\\00044.mp4', 'traindata\\\\00045.mp4', 'traindata\\\\00046.mp4', 'traindata\\\\00047.mp4', 'traindata\\\\00048.mp4', 'traindata\\\\00049.mp4', 'traindata\\\\00050.mp4']\n"
     ]
    }
   ],
   "source": [
    "trainfiles = []\n",
    "\n",
    "trainfiles = glob.glob(os.path.join(os.path.join('traindata'), \"*.mp4\"))\n",
    "trainfiles.sort(key=sortme)\n",
    "print(trainfiles)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for each in trainfiles:\n",
    "    frameExtractor(each, os.path.join(os.getcwd(), \"frames\"), count)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "files = []\n",
    "files = glob.glob(os.path.join(os.path.join(os.getcwd(),\"frames\"), \"*.png\"))\n",
    "sorted(files)\n",
    "\n",
    "train_vectors = []\n",
    "\n",
    "for each in files:\n",
    "    png = cv2.imread(each)\n",
    "    png = cv2.cvtColor(png, cv2.COLOR_RGB2GRAY)\n",
    "    results = HandShapeFeatureExtractor.get_instance().extract_feature(png)\n",
    "    #results = np.squeeze(results)\n",
    "    train_vectors.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5d93e6b-514f-459b-b222-102f3424ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfiles = []\n",
    "\n",
    "testfiles = glob.glob(os.path.join(os.path.join('test'), \"*.mp4\"))\n",
    "#testfiles.sort(key=sortme)\n",
    "sorted(testfiles)\n",
    "\n",
    "count = 0\n",
    "for each in testfiles:\n",
    "    frameExtractor(each, os.path.join(os.getcwd(), \"frames\"), count)\n",
    "    count += 1\n",
    "\n",
    "frames_path = os.path.join(os.getcwd(), \"frames\")\n",
    "files = []\n",
    "files = glob.glob(os.path.join(frames_path, \"*.png\"))\n",
    "sorted(files)\n",
    "test_vectors = []\n",
    "images=[]\n",
    "new_count=0\n",
    "for each in files:\n",
    "    if new_count==count:\n",
    "        break\n",
    "    png = cv2.imread(each)\n",
    "    png = cv2.cvtColor(png, cv2.COLOR_BGR2GRAY)\n",
    "    results = HandShapeFeatureExtractor.get_instance().extract_feature(png)\n",
    "    #results = np.squeeze(results)\n",
    "    test_vectors.append(results)\n",
    "    images.append(os.path.basename(each))\n",
    "    new_count +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fd13be1-5d0d-491c-815e-c9c11e56542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 17, 44, 28, 14, 14, 1, 44, 29, 44, 17, 41, 17, 40, 15, 7, 36]\n"
     ]
    }
   ],
   "source": [
    "res=[]\n",
    "for each in test_vectors:\n",
    "    lst = []\n",
    "    for eachin in train_vectors:\n",
    "        #lst.append(sp.distance.cosine(each, eachin))\n",
    "        lst.append(cosine_similarity(each,eachin))\n",
    "        gesture_num = lst.index(max(lst))\n",
    "        gesture_num = gesture_num\n",
    "    res.append(gesture_num)\n",
    "print(res)\n",
    "np.savetxt(\"Results.csv\", res, delimiter=\",\", fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
